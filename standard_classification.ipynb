{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fce82a3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import praw\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "import csv\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8f7f7bc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cospiracy_detector(text):\n",
    "# function used to classify a comment or a submission by content analysis\n",
    "\n",
    "    alien=[\n",
    "        \"extraterrestrial\",\n",
    "        \"alien\",\n",
    "        \"ufo\",\n",
    "        \"close encounters\",\n",
    "        \"area 51\",\n",
    "        \"roswell\",\n",
    "        \"aliens\",\n",
    "        \"crop circles\",\n",
    "        \"secret space program\",\n",
    "        \"intergalactic\",\n",
    "        \"interstellar\",\n",
    "        \"encounters\",\n",
    "        \"invasion\",\n",
    "        \"civilizations\",\n",
    "        \"universe\"\n",
    "    ]\n",
    "\n",
    "    covid= [\n",
    "        \"vaccination\",\n",
    "        \"vaccine\",\n",
    "        \"anti-vax\",\n",
    "        \"vax\"\n",
    "        \"side effects\",\n",
    "        \"big pharma\",\n",
    "        \"pharmaceutical\",\n",
    "        \"ingredients\",\n",
    "        \"vaccine efficacy\",\n",
    "        \"autism\",\n",
    "        \"pfizer\",\n",
    "        \"astrazeneca\",\n",
    "        \"moderna\",\n",
    "        \"janssen\",\n",
    "        \"coronavirus\",\n",
    "        \"covid\",\n",
    "        \"lab\",\n",
    "        \"bioweapon\",\n",
    "        \"manmade\",\n",
    "        \"gates\",\n",
    "        \"pirbirght\",\n",
    "        \"wuhan\",\n",
    "        \"plandemic\",\n",
    "        \"pandemic\",\n",
    "        \"natural remedies\",\n",
    "        \"alternative cures\",\n",
    "        \"false positive tests\",\n",
    "        \"mask\",\n",
    "        \"corona\",\n",
    "        \"sars\",\n",
    "        \"virus\"\n",
    "        \"event 201\",\n",
    "        \"hydroxychloroquine\"]\n",
    "\n",
    "    chem = [\n",
    "        \"chemtrails\",\n",
    "        \"aerosol spraying\",\n",
    "        \"geoengineering\",\n",
    "        \"chemical trails\",\n",
    "        \"persistent contrails\",\n",
    "        \"aluminum\",\n",
    "        \"barium\",\n",
    "        \"stratospheric aerosol injection\",\n",
    "        \"weather manipulation\",\n",
    "        \"toxic chemicals\",\n",
    "        \"climate engineering\",\n",
    "        \"haarp\",\n",
    "        \"chemtrail\",\n",
    "        \"sky spraying\",\n",
    "        \"airborne chemicals\",\n",
    "        \"solar radiation \",\n",
    "        \"poison\"\n",
    "        \"climategate\",\n",
    "        \"global warming\",\n",
    "        \"climate data manipulation\",\n",
    "        \"artificial climate\",\n",
    "        \"nwo\",\n",
    "        \"climate\",\n",
    "        \"agenda 21\",\n",
    "        \"controlled climate\",\n",
    "        \"artificial sun\"\n",
    "    ]\n",
    "\n",
    "\n",
    "    religion = [\n",
    "        \"new world order\",\n",
    "        \"vatican\",\n",
    "        \"illuminati\",\n",
    "        \"secret society\",\n",
    "        \"divine bloodline\",\n",
    "        \"false prophets\",\n",
    "        \"cults\",\n",
    "        \"satanic rituals\",\n",
    "        \"power and control\",\n",
    "        \"secret societies\",\n",
    "        \"templars\",\n",
    "        \"prophecy\",\n",
    "        \"religious\",\n",
    "        \"indoctrination\",\n",
    "        \"bloodlines\",\n",
    "    ]\n",
    "\n",
    "    flat_earth = [\n",
    "        \"flat earth\",\n",
    "        \"earth plane\",\n",
    "        \"horizon\",\n",
    "        \"antartica\",\n",
    "        \"photographic evidence\",\n",
    "        \"gravity hoax\",\n",
    "        \"geocentrism\",\n",
    "        \"zetecism\",\n",
    "        \"ice wall\",\n",
    "        \"map projection\",\n",
    "        \"round earth\",\n",
    "        \"cosmology\",\n",
    "        \"globe deception\",\n",
    "        \"hollow earth\"\n",
    "    ]\n",
    "\n",
    "    fiveg= [\n",
    "        \"5g\",\n",
    "        \"radiation\",\n",
    "        \"health risks\",\n",
    "        \"surveillance\",\n",
    "        \"electromagnetic waves\",\n",
    "        \"weaponization\",\n",
    "        \"digital tyranny\",\n",
    "        \"cancer\",\n",
    "        \"environmental impact\",\n",
    "        \"5g towers\",\n",
    "        \"frequency control\",\n",
    "        \"surveillance state\",\n",
    "        \"digital control\",\n",
    "        \"privacy invasion\",\n",
    "        \"wireless radiation\",\n",
    "        \"smart grid\",\n",
    "        \"internet of things\",\n",
    "        \"secret agenda\",\n",
    "        \"control of information\",\n",
    "        \"dna alteration\",\n",
    "        \"technology-induced illnesses\",\n",
    "        \"global depopulation\",\n",
    "        \"mk-ultra\",\n",
    "        \"hypnosis\",\n",
    "        \"manchurian candidate\",\n",
    "        \"electromagnetic\",\n",
    "        \"behavior modification\",\n",
    "        \"psychotronic\",\n",
    "        \"microwave\"]\n",
    "    cosp=[]\n",
    "    i=0\n",
    "    if (any(word in text for word in alien)==1):\n",
    "        cosp.append('alien')\n",
    "        i+= 1\n",
    "    if(any(word in text for word in covid)==1):\n",
    "        cosp.append('covid')\n",
    "        i+= 1\n",
    "    if (any(word in text for word in religion)==1):\n",
    "        cosp.append('religion')\n",
    "        i+= 1\n",
    "    if (any(word in text for word in chem)==1):\n",
    "        cosp.append('chem')\n",
    "        i+= 1\n",
    "    if (any(word in text for word in fiveg)==1):\n",
    "        cosp.append('5g')\n",
    "        i+= 1\n",
    "    if (any(word in text for word in flat_earth)==1):\n",
    "        cosp.append('flat_earth')\n",
    "        i+= 1\n",
    "    if(i==0):\n",
    "        cosp.append('neutral')\n",
    "    return cosp"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "546a1a6f",
   "metadata": {},
   "source": [
    "**submissions from February**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "69dc9f6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loop : 28646it [03:08, 152.05it/s]\n"
     ]
    }
   ],
   "source": [
    "# the label of the post\n",
    "label_post = [] \n",
    "\n",
    "# author of the post\n",
    "author_post = [] \n",
    "\n",
    "# the id of a comment/submission can be trasformed as the parent_id for the replies to this comment/submission adding 't3_' to the\n",
    "# id if we consider a submission while adding 't1_' if we consider a comment\n",
    "bridge_user = {} \n",
    "\n",
    "path_of_the_directory_1 =r\"C:\\Users\\Alessandro Batignani\\Desktop\\sna-2023-2023_batignani_fattorini_iannello\\data_collection\\reddit_parser\\reddit_parser\\raw_data_february\"\n",
    "for files in tqdm(os.scandir(path_of_the_directory_1), desc =\"loop \"):\n",
    "    # Opening JSON file\n",
    "    f = open(files)\n",
    "    # returns JSON object as a dictionary\n",
    "    data = json.load(f)\n",
    "    data=data[\"posts\"]\n",
    "    if (\"02/2020\" in data):\n",
    "        data=data[\"02/2020\"]\n",
    "        for value in data:\n",
    "            \n",
    "            label_post.append(cospiracy_detector(value['clean_text']))\n",
    "            author_post.append(value['author'])\n",
    "            \n",
    "            bridge_user['t3_'+value['id']] = value['author']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b8df4ae",
   "metadata": {},
   "source": [
    "**submissions from March**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2bdb9ddf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loop : 45083it [04:56, 152.27it/s]\n"
     ]
    }
   ],
   "source": [
    "path_of_the_directory_2 =r\"C:\\Users\\Alessandro Batignani\\Desktop\\sna-2023-2023_batignani_fattorini_iannello\\data_collection\\reddit_parser\\reddit_parser\\raw_data_march\"\n",
    "for files in tqdm(os.scandir(path_of_the_directory_2), desc =\"loop \"):\n",
    "    \n",
    "    # Opening JSON file\n",
    "    f = open(files)\n",
    "    # returns JSON object as a dictionary\n",
    "    data = json.load(f)\n",
    "    data=data[\"posts\"]\n",
    "    if (\"03/2020\" in data):\n",
    "        data=data[\"03/2020\"]\n",
    "        for value in data:\n",
    "            \n",
    "            label_post.append(cospiracy_detector(value['clean_text']))\n",
    "            author_post.append(value['author'])\n",
    "            \n",
    "            bridge_user['t3_'+value['id']] = value['author']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce04c004",
   "metadata": {},
   "source": [
    "**comments from February**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a44101b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loop : 28646it [00:14, 1942.33it/s]\n"
     ]
    }
   ],
   "source": [
    "# parent id of the comment\n",
    "parent_comm = [] \n",
    "\n",
    "# author of the comment\n",
    "author_comm = [] \n",
    "\n",
    "# label of the comment\n",
    "label_comm = [] \n",
    "\n",
    "# creation-time of the comment\n",
    "time_comm = [] \n",
    "\n",
    "for files in tqdm(os.scandir(path_of_the_directory_1), desc =\"loop \"):\n",
    "    # Opening JSON file\n",
    "    f = open(files)\n",
    "    # returns JSON object as a dictionary\n",
    "    data = json.load(f)\n",
    "    data=data[\"comments\"]\n",
    "    if (\"02/2020\" in data):\n",
    "        data=data[\"02/2020\"]\n",
    "        for value in data:\n",
    "            \n",
    "            label_comm.append(cospiracy_detector(value['clean_text']))\n",
    "            author_comm.append(value['author'])\n",
    "            parent_comm.append(value['parent_id']) \n",
    "            time_comm.append(value['created_utc'])\n",
    "            \n",
    "            bridge_user['t1_'+value['id']] = value['author']\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0730b5fb",
   "metadata": {},
   "source": [
    "**comments from March**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7fdce25e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loop : 45083it [00:22, 2030.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 22.2 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "for files in tqdm(os.scandir(path_of_the_directory_2), desc =\"loop \"):\n",
    "    # Opening JSON file\n",
    "    f = open(files)\n",
    "    # returns JSON object as a dictionary\n",
    "    data = json.load(f)\n",
    "    data=data[\"comments\"]\n",
    "    if (\"03/2020\" in data):\n",
    "        data=data[\"03/2020\"]\n",
    "        for value in data:\n",
    "            \n",
    "            label_comm.append(cospiracy_detector(value['clean_text']))\n",
    "            author_comm.append(value['author'])\n",
    "            parent_comm.append(value['parent_id']) \n",
    "            time_comm.append(value['created_utc'])\n",
    "            \n",
    "            bridge_user['t1_'+value['id']] = value['author']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4b6d30e",
   "metadata": {},
   "source": [
    "### classification of submissions' authors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6a773d03",
   "metadata": {},
   "outputs": [],
   "source": [
    "# it needs to update the label of a user\n",
    "\n",
    "def update_node(user, kw):\n",
    "    \n",
    "# user is the list of the current label of the user \n",
    "# kw : list of the fields of the new submission\\comment\n",
    "\n",
    "    # if what I add is 'neutral' there is no update\n",
    "    if 'neutral' in kw: \n",
    "        return user\n",
    "    \n",
    "    # if the current label of the user is 'neutral' we return the label of new submission/comment\n",
    "    if 'neutral' in user:\n",
    "        return kw\n",
    "    \n",
    "    # we add no redundant label \n",
    "    else:\n",
    "        for x in range(len(kw)):\n",
    "            if kw[x] not in user:\n",
    "                user.append(kw[x])\n",
    "        \n",
    "    return user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f46e1066",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 15 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# reminder:\n",
    "# label_post list of fields of the submissions, author_post list of authors of the submissions\n",
    "\n",
    "# WARNING: user_list is aa dict not a list!\n",
    "users_list = {} # 'name of user' the key , [list of the user's label] the value of the dict\n",
    "\n",
    "for x in range(len(author_post)):\n",
    "    if author_post[x] not in users_list:\n",
    "        users_list[author_post[x]]= label_post[x]\n",
    "    else:\n",
    "        users_list[author_post[x]]= update_node(users_list[author_post[x]], label_post[x])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17e3decc",
   "metadata": {},
   "source": [
    "### classification of comments' authors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b60f5ba5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 344 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# reminder:\n",
    "# label_comm list of fields of the comments, author_comm list of authors of the comment\n",
    "\n",
    "for x in range(len(author_comm)):\n",
    "    if author_comm[x] not in users_list:\n",
    "        users_list[author_comm[x]]= label_comm[x]\n",
    "    else:\n",
    "        users_list[author_comm[x]] = update_node(users_list[author_comm[x]], label_comm[x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5776193c",
   "metadata": {},
   "outputs": [],
   "source": [
    "username_list = list(users_list) # name of users who made a comment/post"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c6bc0b4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we separate user_list in neutral and non neutral users\n",
    "neutral_users = {} \n",
    "non_neutral_users = {} \n",
    "\n",
    "for x in range(len(username_list)):\n",
    "    node_fields = users_list[username_list[x]]\n",
    "    if 'neutral' in node_fields:\n",
    "        neutral_users[username_list[x]] = node_fields\n",
    "    else:\n",
    "        non_neutral_users[username_list[x]] = node_fields"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "604cb677",
   "metadata": {},
   "source": [
    "### network construction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cb8cfdcf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 1.72 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# first we add to the network non neutral users (author_1) who made (author_1) to generic users(author_2)\n",
    "# we add both author_1 and author_2. Up to now are not allowed links among neutral users\n",
    "\n",
    "g = nx.Graph()\n",
    "\n",
    "# it needs to save the info. about the  interactions used to build the network (author_1, author_2, creation time)\n",
    "# author_1 replies to author_2's submission/post at the creation time\n",
    "csv_list = [] \n",
    "\n",
    "# bridge_user is used to connected author_1 and author_2\n",
    "for x in range(len(author_comm)):\n",
    "    author_1 = author_comm[x]\n",
    "    if author_1 in non_neutral_users and parent_comm[x] in bridge_user:\n",
    "        author_2 = bridge_user[parent_comm[x]]\n",
    "        csv_list.append([author_1, author_2, time_comm[x]])\n",
    "        g.add_edge(author_1, author_2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8e8db661",
   "metadata": {},
   "outputs": [],
   "source": [
    "nodes_list = list(g.nodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "64903405",
   "metadata": {},
   "outputs": [],
   "source": [
    "# classification of graph's nodes in neutral and non-neutral nodes\n",
    "\n",
    "non_neutral_nodes = {}\n",
    "neutral_nodes = {}\n",
    "\n",
    "for x in range(len(nodes_list)):\n",
    "    node = nodes_list[x]\n",
    "    if node in non_neutral_users:\n",
    "        non_neutral_nodes[node] = non_neutral_users[node]\n",
    "    else:\n",
    "        neutral_nodes[node] = neutral_users[node]\n",
    "    \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "22ffb783",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 239 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# now we add links among neutral nodes already present in the network\n",
    "for x in range(len(author_comm)):\n",
    "    author_1 = author_comm[x]\n",
    "    if author_1 in neutral_nodes and parent_comm[x] in bridge_user:\n",
    "        author_2 = bridge_user[parent_comm[x]]\n",
    "        if author_2 in neutral_nodes:\n",
    "            csv_list.append([author_1, author_2, time_comm[x], neutral_nodes[author_1]])\n",
    "            g.add_edge(author_1, author_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5718139",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('conspiracy_2m_final.csv','w',newline='') as csvfile:\n",
    "    writer=csv.writer(csvfile)\n",
    "    for x in range(len(csv_list)):\n",
    "        writer.writerow([csv_list[x][0], csv_list[x][1], csv_list[x][2]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7030838",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('conspiracy_2m_attr.csv','w',newline='') as csvfile:\n",
    "    writer=csv.writer(csvfile)\n",
    "    for x in range(len(nodes_list)):\n",
    "        if nodes_list[x] in non_neutral_nodes:\n",
    "            writer.writerow([nodes_list[x], ','.join(non_neutral_nodes[nodes_list[x]])])\n",
    "        else:\n",
    "            writer.writerow([nodes_list[x], ','.join(neutral_nodes[nodes_list[x]])])          "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ed363c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#remove 'rConBot' a moderator of the subreddit r/conspiracy\n",
    "g.remove_node('rConBot')\n",
    "#remove the selfloops\n",
    "g.remove_edges_from(nx.selfloop_edges(g))\n",
    "#remove isolated nodes\n",
    "g.remove_nodes_from(list(nx.isolates(g)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
